{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10725266,"sourceType":"datasetVersion","datasetId":6648899}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch accelerate bitsandbytes jiwer datasets peft loralib tqdm pytesseract\n!apt-get install tesseract-ocr\n!apt-get install tesseract-ocr-eng","metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2025-03-18T15:08:50.663001Z","iopub.execute_input":"2025-03-18T15:08:50.663205Z","iopub.status.idle":"2025-03-18T15:09:05.055522Z","shell.execute_reply.started":"2025-03-18T15:08:50.663186Z","shell.execute_reply":"2025-03-18T15:09:05.054332Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nCollecting click>=8.1.8 (from jiwer)\n  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nDownloading click-8.1.8-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, loralib, click, jiwer, bitsandbytes\n  Attempting uninstall: click\n    Found existing installation: click 8.1.7\n    Uninstalling click-8.1.7:\n      Successfully uninstalled click-8.1.7\nSuccessfully installed bitsandbytes-0.45.3 click-8.1.8 jiwer-3.1.0 loralib-0.1.2 rapidfuzz-3.12.2\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\n0 upgraded, 0 newly installed, 0 to remove and 117 not upgraded.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\ntesseract-ocr-eng set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 117 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import ( LlamaForCausalLM, LlamaTokenizer, AutoProcessor, AutoModelForVision2Seq, TrainingArguments, Trainer, BitsAndBytesConfig )\nfrom datasets import Dataset, load_dataset\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nimport jiwer\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport json\nfrom glob import glob\nimport random\nimport pytesseract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:09:09.093907Z","iopub.execute_input":"2025-03-18T15:09:09.094221Z","iopub.status.idle":"2025-03-18T15:09:31.753119Z","shell.execute_reply.started":"2025-03-18T15:09:09.094191Z","shell.execute_reply":"2025-03-18T15:09:31.752407Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n\nfrom huggingface_hub import login\n\nlogin(token=HF_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:09:35.246625Z","iopub.execute_input":"2025-03-18T15:09:35.247316Z","iopub.status.idle":"2025-03-18T15:09:35.426824Z","shell.execute_reply.started":"2025-03-18T15:09:35.247283Z","shell.execute_reply":"2025-03-18T15:09:35.426214Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:09:38.352307Z","iopub.execute_input":"2025-03-18T15:09:38.352731Z","iopub.status.idle":"2025-03-18T15:09:38.440132Z","shell.execute_reply.started":"2025-03-18T15:09:38.352691Z","shell.execute_reply":"2025-03-18T15:09:38.439233Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"\n\n# Load Images from the folder and Cropping them","metadata":{}},{"cell_type":"code","source":"def load_images_from_folder(folder):\n    images = []\n    image_names = []\n    for filename in os.listdir(folder):\n        if filename.endswith(\".jpg\"):\n            img_path = os.path.join(folder, filename)\n            img = Image.open(img_path).convert(\"RGB\")\n            images.append(img)\n            image_names.append(filename)\n    return images, image_names\n\nimage_folder = \"/kaggle/input/dataset/images\"\ndataset, image_names = load_images_from_folder(image_folder)\nprint(\"Loaded images successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:09:45.825079Z","iopub.execute_input":"2025-03-18T15:09:45.825366Z","iopub.status.idle":"2025-03-18T15:09:51.085934Z","shell.execute_reply.started":"2025-03-18T15:09:45.825345Z","shell.execute_reply":"2025-03-18T15:09:51.084813Z"}},"outputs":[{"name":"stdout","text":"Loaded images successfully\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def crop_and_save_images(images, image_names, output_folder):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    cropped_images = []\n    cropped_image_names = []\n\n    for img, filename in zip(images, image_names):\n        width, height = img.size\n        left = width // 22\n        upper = 0\n        right = width\n        lower = height - (height // 12.2)\n        crop_box = (left, upper, right, lower)\n\n        cropped_img = img.crop(crop_box)\n        \n        cropped_img_path = os.path.join(output_folder, filename)\n        cropped_img.save(cropped_img_path)\n\n        cropped_images.append(cropped_img)\n        cropped_image_names.append(filename)\n\n    return cropped_images, cropped_image_names\n\ncropped_image_folder = \"/kaggle/working/cropped_images\"\n\ncropped_dataset, cropped_image_names = crop_and_save_images(dataset, image_names, cropped_image_folder)\n\nprint(\"Cropped dataset created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T11:52:23.696255Z","iopub.execute_input":"2025-02-19T11:52:23.696589Z","iopub.status.idle":"2025-02-19T11:52:27.636814Z","shell.execute_reply.started":"2025-02-19T11:52:23.696561Z","shell.execute_reply":"2025-02-19T11:52:27.635965Z"}},"outputs":[{"name":"stdout","text":"Cropped dataset created successfully!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Generate True text from the images using OCR\ntakes about 12-15 min to generate text","metadata":{}},{"cell_type":"code","source":"def generate_ground_truth(images, image_names):\n    ground_truth = {}\n    for img, name in zip(images, image_names):\n        text = pytesseract.image_to_string(img).strip()\n        if not text:  # If OCR fails\n            text = \"N/A\"\n        ground_truth[name] = text\n    return ground_truth\n\nground_truth_data = generate_ground_truth(cropped_dataset, cropped_image_names)\n# true_texts = [ground_truth_data[img_name] for img_name in image_names]\nprint(\"true_texts generated\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T11:56:09.190894Z","iopub.execute_input":"2025-02-19T11:56:09.191199Z","iopub.status.idle":"2025-02-19T11:56:19.850250Z","shell.execute_reply.started":"2025-02-19T11:56:09.191176Z","shell.execute_reply":"2025-02-19T11:56:19.849370Z"}},"outputs":[{"name":"stdout","text":"true_texts generated\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Creating and Loading the model \"Llama-3.2-11B-Vision\"\nLoaded a 4-bit quantized llama-3.2-11B-vision model. *Note: Loading the model can take upto 10 minutes as the model is 22GB big to download*","metadata":{}},{"cell_type":"code","source":"def load_model():\n    model_name = \"meta-llama/Llama-3.2-11B-Vision\"\n\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_use_double_quant=True\n    )\n\n    model = AutoModelForVision2Seq.from_pretrained(\n        model_name,\n        quantization_config=quantization_config,\n        device_map=\"auto\",\n        torch_dtype=torch.float16\n    )\n\n    processor = AutoProcessor.from_pretrained(model_name)\n\n    return model, processor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:59:32.193196Z","iopub.execute_input":"2025-03-18T15:59:32.193496Z","iopub.status.idle":"2025-03-18T15:59:32.197813Z","shell.execute_reply.started":"2025-03-18T15:59:32.193474Z","shell.execute_reply":"2025-03-18T15:59:32.196945Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model, processor = load_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T15:59:35.811864Z","iopub.execute_input":"2025-03-18T15:59:35.812159Z","iopub.status.idle":"2025-03-18T16:03:15.562495Z","shell.execute_reply.started":"2025-03-18T15:59:35.812135Z","shell.execute_reply":"2025-03-18T16:03:15.561804Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/5.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad453f441914bd9a04800d0a46900ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/89.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"270d3a446f304025a04936e33f42918e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85586736a9de4f4284f7c4ce972bac8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84ffdff117764b4d81c4e362d76ed3f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"220d187340fd431c9c6c0f9676a5cc46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56b77a7cbdd46a283c8c61f2b9dcd90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"facb8478dd7d4c59b186debba1d1cc30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfda364da2ca4f5dae48213062700232"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efef6e8fe9fe4a7ca77e957c3aa188a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/152 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372f473beae444de9849b7d13350c2dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02dfb8e5caeb42d487f7717334b0bd86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6ed42958d04e02a0fe1d0b8f78db0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"812879ced01d41e9835442ddf3d5a02b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cdcf57fed1e4edeb8222a3a89554d01"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"#  Extract baseline texts using the model\n* Took about 1.5 hours to extract text using the model if the max_length put to be 256.\n* And would take 3 hours for max_length=512.","metadata":{}},{"cell_type":"code","source":"# def extract_text(images,model,processor):\n#     texts = []\n#     for img in tqdm(images):\n#         inputs = processor(images=img, return_tensors=\"pt\").to(device)\n#         outputs = model.generate(**inputs,max_length=256,num_beams=5,early_stopping=True)\n#         text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n#         texts.append(text)\n#     return texts\n\n# baseline_texts = extract_text(cropped_dataset,model,processor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.amp import autocast","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:04:09.523766Z","iopub.execute_input":"2025-03-18T16:04:09.524117Z","iopub.status.idle":"2025-03-18T16:04:09.527873Z","shell.execute_reply.started":"2025-03-18T16:04:09.524093Z","shell.execute_reply":"2025-03-18T16:04:09.526969Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:04:13.656707Z","iopub.execute_input":"2025-03-18T16:04:13.657072Z","iopub.status.idle":"2025-03-18T16:04:13.660924Z","shell.execute_reply.started":"2025-03-18T16:04:13.657040Z","shell.execute_reply":"2025-03-18T16:04:13.659951Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def extract_text(images, model, processor, batch_size=4):\n    texts = []\n    \n    device = next(model.parameters()).device\n    \n    for i in tqdm(range(0, len(images), batch_size)):\n        batch = images[i:i+batch_size]\n        \n        inputs = processor(images=batch, return_tensors=\"pt\", padding=True).to(device)\n        \n        with autocast('cuda'):\n            outputs = model.generate(**inputs, max_length=512, num_beams=2, early_stopping=True)\n        \n        batch_texts = processor.batch_decode(outputs, skip_special_tokens=True)\n        texts.extend(batch_texts)\n    \n    return texts\n\nbaseline_texts = extract_text(cropped_dataset, model, processor, batch_size=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:04:45.841467Z","iopub.execute_input":"2025-02-18T15:04:45.841775Z","iopub.status.idle":"2025-02-18T18:30:18.539890Z","shell.execute_reply.started":"2025-02-18T15:04:45.841754Z","shell.execute_reply":"2025-02-18T18:30:18.539114Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 39/39 [3:25:32<00:00, 316.22s/it]  \n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Text Organization\nCleaning the texts using regular expression for removing some unnecessary characters","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download('punkt_tab')\n\ndef clean_text(text):\n    text = text.strip()  # Remove leading and trailing spaces\n    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n    text = re.sub(r'\\n+', ' ', text)  # Remove excessive newlines\n    text = text.replace(\"  \", \" \")  # Remove double spaces\n    return text\n\ndef structure_text(text):\n    sentences = sent_tokenize(text)  # Tokenize into sentences\n    structured_text = \"\\n\".join(sentences)  # Join sentences with newline\n    return structured_text\n\ndef process_extracted_text(extracted_texts):\n    organized_texts = []\n    for text in extracted_texts:\n        cleaned = clean_text(text)\n        structured = structure_text(cleaned)\n        organized_texts.append(structured)\n    \n    return organized_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:30:32.438689Z","iopub.execute_input":"2025-02-18T18:30:32.438977Z","iopub.status.idle":"2025-02-18T18:30:32.493780Z","shell.execute_reply.started":"2025-02-18T18:30:32.438954Z","shell.execute_reply":"2025-02-18T18:30:32.493129Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"def batch_list(data, batch_size):\n    return [\"\".join(data[i:i + batch_size]) for i in range(0, len(data), batch_size)]\n    \nbatch_true_text=batch_list(true_texts,4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:30:36.351844Z","iopub.execute_input":"2025-02-18T18:30:36.352157Z","iopub.status.idle":"2025-02-18T18:30:36.356624Z","shell.execute_reply.started":"2025-02-18T18:30:36.352132Z","shell.execute_reply":"2025-02-18T18:30:36.355744Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"processed_true_texts = process_extracted_text(batch_true_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:30:44.334028Z","iopub.execute_input":"2025-02-18T18:30:44.334340Z","iopub.status.idle":"2025-02-18T18:30:44.488941Z","shell.execute_reply.started":"2025-02-18T18:30:44.334318Z","shell.execute_reply":"2025-02-18T18:30:44.488355Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"processed_predicted_texts=process_extracted_text(baseline_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:30:53.450722Z","iopub.execute_input":"2025-02-18T18:30:53.451026Z","iopub.status.idle":"2025-02-18T18:30:53.491950Z","shell.execute_reply.started":"2025-02-18T18:30:53.450996Z","shell.execute_reply":"2025-02-18T18:30:53.491293Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"# Evaluating texts i.e. calculating words error and character error\n* The error comes to be quite high because the length of the text generated by the model is much less than the length of actual text as extrated by OCR.","metadata":{}},{"cell_type":"code","source":"from jiwer import wer, cer\ndef evaluate_texts(true_texts, predicted_texts):\n    word_error = wer(true_texts, predicted_texts)\n    char_error = cer(true_texts, predicted_texts)\n    return word_error, char_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:15:53.740495Z","iopub.execute_input":"2025-03-18T16:15:53.740795Z","iopub.status.idle":"2025-03-18T16:15:53.744800Z","shell.execute_reply.started":"2025-03-18T16:15:53.740770Z","shell.execute_reply":"2025-03-18T16:15:53.744065Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"baseline_wer,baseline_cer = evaluate_texts(processed_true_texts, processed_predicted_texts)\nprint(f\"Word Error Rate: {baseline_wer}\")\nprint(f\"Character Error Rate: {baseline_cer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:30:58.411265Z","iopub.execute_input":"2025-02-18T18:30:58.411579Z","iopub.status.idle":"2025-02-18T18:30:59.226097Z","shell.execute_reply.started":"2025-02-18T18:30:58.411551Z","shell.execute_reply":"2025-02-18T18:30:59.225399Z"}},"outputs":[{"name":"stdout","text":"Word Error Rate: 0.9389887895066583\nCharacter Error Rate: 0.8649555021604397\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Fine tune the model using LoRA (Low Rank Adaptation)\n* training the model and obtaining the fine_tuned model took quite longer approax. 6-7 hours ","metadata":{}},{"cell_type":"code","source":"# def prepare_dataset(images, true_texts, processor):\n#     pixel_values_list = []\n#     input_ids_list = []\n    \n#     for img, text in zip(images, true_texts):\n#         image_features = processor(images=img, return_tensors=\"pt\")\n#         pixel_values_list.append(image_features[\"pixel_values\"][0])\n        \n#         text_features = processor(text=text, return_tensors=\"pt\", padding=\"max_length\", max_length=256)\n#         input_ids_list.append(text_features[\"input_ids\"][0])\n    \n#     dataset_dict = {\n#         \"pixel_values\": pixel_values_list,\n#         \"labels\": input_ids_list\n#     }\n    \n#     dataset = Dataset.from_dict(dataset_dict)\n    \n#     dataset = dataset.train_test_split(test_size=0.1, seed=42)\n#     return dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_dataset_batch(images, true_texts, processor, batch_size=4):\n    pixel_values = []\n    input_ids = []\n    \n    # Process images in batches\n    for i in range(0, len(images), batch_size):\n        batch_images = images[i:i+batch_size]\n        batch_texts = [\"\".join(true_texts[i:i + batch_size])]\n        \n        # Process image batch\n        image_features = processor(\n            images=batch_images, \n            return_tensors=\"pt\",\n            padding=True\n        )\n        pixel_values.extend(image_features[\"pixel_values\"])\n        \n        # Process text batch\n        text_features = processor(\n            text=batch_texts,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=512,\n            truncation=True\n        )\n        input_ids.extend(text_features[\"input_ids\"])\n        \n    print(len(pixel_values))\n    print(len(input_ids))\n    return Dataset.from_dict({\n        \"pixel_values\": pixel_values,\n        \"labels\": input_ids\n    }).train_test_split(test_size=0.1, seed=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:59:45.874676Z","iopub.execute_input":"2025-02-18T19:59:45.874977Z","iopub.status.idle":"2025-02-18T19:59:45.880478Z","shell.execute_reply.started":"2025-02-18T19:59:45.874950Z","shell.execute_reply":"2025-02-18T19:59:45.879626Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# def collate_fn(batch):\n#     pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n#     labels = torch.stack([item[\"labels\"] for item in batch])\n    \n#     return {\n#         \"pixel_values\": pixel_values,\n#         \"labels\": labels\n#     }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:48:18.738109Z","iopub.execute_input":"2025-02-18T19:48:18.738403Z","iopub.status.idle":"2025-02-18T19:48:18.741591Z","shell.execute_reply.started":"2025-02-18T19:48:18.738381Z","shell.execute_reply":"2025-02-18T19:48:18.740771Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"def configure_lora(model):\n    lora_config = LoraConfig(\n        r=16,\n        lora_alpha=32,\n        target_modules=[\"q_proj\", \"v_proj\"],\n        lora_dropout=0.05,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n    \n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, lora_config)\n    model.print_trainable_parameters()\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:59:20.004733Z","iopub.execute_input":"2025-02-18T19:59:20.005004Z","iopub.status.idle":"2025-02-18T19:59:20.009159Z","shell.execute_reply.started":"2025-02-18T19:59:20.004983Z","shell.execute_reply":"2025-02-18T19:59:20.008273Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# def train_model(model, dataset, processor):\n#     training_args = TrainingArguments(\n#         output_dir=\"./llama-vision-finetuned\",\n#         num_train_epochs=3,\n#         per_device_train_batch_size=8,\n#         per_device_eval_batch_size=8,\n#         gradient_accumulation_steps=2,\n#         dataloader_num_workers=2,  # parallel loading\n#         learning_rate=2e-4,\n#         weight_decay=0.01,\n#         logging_steps=10,\n#         eval_strategy=\"epoch\",\n#         save_strategy=\"epoch\",\n#         load_best_model_at_end=True,\n#         push_to_hub=False,\n#         remove_unused_columns=False\n#     )\n    \n#     trainer = Trainer(\n#         model=model,\n#         args=training_args,\n#         train_dataset=dataset[\"train\"],\n#         eval_dataset=dataset[\"test\"],\n#         data_collator=collate_fn,\n#     )\n    \n#     trainer.train()\n#     return trainer, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:48:09.825713Z","iopub.execute_input":"2025-02-18T19:48:09.826025Z","iopub.status.idle":"2025-02-18T19:48:09.829933Z","shell.execute_reply.started":"2025-02-18T19:48:09.825998Z","shell.execute_reply":"2025-02-18T19:48:09.829083Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"from transformers import TrainerCallback, TrainingArguments, Trainer\nfrom tqdm import tqdm\n\nclass ProgressBarCallback(TrainerCallback):\n    def __init__(self, total_steps):\n        self.pbar = tqdm(total=total_steps, desc=\"Training Progress\")\n\n    def on_step_end(self, args, state, control, **kwargs):\n        self.pbar.update(1)\n\n    def on_train_end(self, args, state, control, **kwargs):\n        self.pbar.close()\n\ndef train_model(model, dataset, processor):\n    training_args = TrainingArguments(\n        output_dir=\"./llama-vision-finetuned\",\n        num_train_epochs=3,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        gradient_accumulation_steps=2,\n        dataloader_num_workers=2,\n        learning_rate=2e-4,\n        weight_decay=0.01,\n        logging_steps=10,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        push_to_hub=False,\n        remove_unused_columns=False\n    )\n\n    total_steps = (len(dataset[\"train\"]) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)) * training_args.num_train_epochs\n    progress_callback = ProgressBarCallback(total_steps)\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[\"train\"],\n        eval_dataset=dataset[\"test\"],\n        data_collator=collate_fn,\n        callbacks=[progress_callback]  # Attach the progress bar\n    )\n\n    trainer.train()\n    return trainer, model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:59:23.244763Z","iopub.execute_input":"2025-02-18T19:59:23.245121Z","iopub.status.idle":"2025-02-18T19:59:23.251703Z","shell.execute_reply.started":"2025-02-18T19:59:23.245087Z","shell.execute_reply":"2025-02-18T19:59:23.250767Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# Prepare dataset\ndataset = prepare_dataset_batch(cropped_dataset, true_texts, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T19:59:50.926339Z","iopub.execute_input":"2025-02-18T19:59:50.926613Z","iopub.status.idle":"2025-02-18T20:00:18.518586Z","shell.execute_reply.started":"2025-02-18T19:59:50.926591Z","shell.execute_reply":"2025-02-18T20:00:18.517832Z"}},"outputs":[{"name":"stdout","text":"39\n39\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# Configure and fine-tune model\nmodel_finetuned = configure_lora(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:00:20.163556Z","iopub.execute_input":"2025-02-18T20:00:20.163837Z","iopub.status.idle":"2025-02-18T20:00:20.760952Z","shell.execute_reply.started":"2025-02-18T20:00:20.163814Z","shell.execute_reply":"2025-02-18T20:00:20.760220Z"}},"outputs":[{"name":"stdout","text":"trainable params: 11,796,480 || all params: 10,654,737,955 || trainable%: 0.1107\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"trainer, model_finetuned = train_model(model_finetuned, dataset, processor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"finetuned_texts=extract_text(cropped_dataset,model_finetuned,processor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"organised_finetuned_texts=process_extracted_text(finetuned_texts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"finetuned_wer, finetuned_cer = evaluate_texts(true_texts, organized_finetuned_texts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Baseline Model Performance:\")\nprint(f\"Word Error Rate: {baseline_wer:.4f}\")\nprint(f\"Character Error Rate: {baseline_cer:.4f}\")\n\nprint(\"\\nFine-tuned Model Performance:\")\nprint(f\"Word Error Rate: {finetuned_wer:.4f}\")\nprint(f\"Character Error Rate: {finetuned_cer:.4f}\")\n\nprint(\"\\nImprovement:\")\nprint(f\"Word Error Rate Improvement: {(baseline_wer - finetuned_wer) * 100:.2f}%\")\nprint(f\"Character Error Rate Improvement: {(baseline_cer - finetuned_cer) * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}